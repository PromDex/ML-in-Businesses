{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f155fb-b137-4921-8f20-642a0d965f4c",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135704e-b332-4081-8009-49388864a841",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d9ff4-8f45-41ce-95d8-3a8498a6dd59",
   "metadata": {},
   "source": [
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно).\n",
    "Допустим, у нас две модели:\n",
    "\n",
    "первая помечает 100 объектов как класс 1, но TP = 90\n",
    "вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6b0dc-6738-429b-847b-372c2fbfec8d",
   "metadata": {},
   "source": [
    "#### Элементарный код без преобразований данных для трёх популярных вариантов:\n",
    "#### логистическая регрессия, градиентный бустинг и случайный лес.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874dae19-5595-4a8e-8480-d8b1e92b3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('train_case2.csv', ';')\n",
    "#data.head(3)\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop('cardio', axis=1)\n",
    "y = data['cardio']\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa46576d-e520-4a52-9081-b2401247619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6997857142857142\n"
     ]
    }
   ],
   "source": [
    "#Логистическая регрессия:\n",
    "#Логистическая регрессия широко используется для задач классификации.\n",
    "#Она моделирует вероятность отнесения объекта к определенному классу.\n",
    "#Создание и обучение модели логистической регрессии\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовом наборе данных\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a266846-2b8f-4a8a-8c78-0090e0ab909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7368571428571429\n"
     ]
    }
   ],
   "source": [
    "#Градиентный бустинг:\n",
    "#Градиентный бустинг представляет собой ансамблевый метод,\n",
    "#который комбинирует несколько слабых моделей в одну сильную модель.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Создание и обучение модели градиентного бустинга\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовом наборе данных\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d886b4f8-f674-4fc3-bab5-adf1a47a19e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7276428571428571\n"
     ]
    }
   ],
   "source": [
    "# Случайный лес - это ансамблевая модель, состоящая из нескольких решающих деревьев.\n",
    "#Вот пример кода для обучения модели случайного леса:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Создание и обучение модели случайного леса\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовом наборе данных\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489abaf0-3e79-4830-b9f1-ff0b10bd7454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Mean Accuracy: 0.6951428571428572, Standard Deviation: 0.00559208624499197\n",
      "Gradient Boosting: Mean Accuracy: 0.6625857142857143, Standard Deviation: 0.09718668549104194\n",
      "Random Forest: Mean Accuracy: 0.6792142857142857, Standard Deviation: 0.06931579612062994\n",
      "Best Model: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "#чтобы выбрать лучшую модель из трех написанных:\n",
    "#логистической регрессии, градиентного бустинга и случайного леса,\n",
    "#можно использовать кросс-валидацию и сравнить их производительность на основе выбранной метрики оценки. В данном случае мы будем использовать точность (accuracy) в качестве метрики.\n",
    "#пример кода, который поможет вам выбрать лучшую модель:\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Создание моделей\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# Кросс-валидация и оценка моделей\n",
    "for name, model in models:\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Mean Accuracy: {scores.mean()}, Standard Deviation: {scores.std()}\")\n",
    "\n",
    "# Выбор лучшей модели\n",
    "best_model_name, best_model = max(models, key=lambda x: cross_val_score(x[1], X, y, cv=5, scoring='accuracy').mean())\n",
    "print(f\"Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9efd6b-3efc-4995-b7ad-5660611295b7",
   "metadata": {},
   "source": [
    "В случае сильного дисбаланса классов, метрика Precision-Recall Curve может быть более информативной и предпочтительной. В вашем примере первая модель, которая помечает меньшее количество объектов класса \"1\", но имеет одинаковый TP (true positive), будет считаться лучшей с точки зрения precision и recall. Однако, при выборе лучшей модели необходимо учитывать и другие метрики, такие как AUC и F1-score, и принимать решение на основе общей производительности моделей по всем метрикам и требованиям конкретной задачи.\n",
    "\n",
    "В предыдущем коде были обучены и оценены три модели: логистическая регрессия, градиентный бустинг и случайный лес. Теперь мы можем вывести сравнение полученных моделей по метрикам precision, recall, AUC и F1-score в виде таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577714c9-f969-4f05-a653-1a03d7eebf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Precision    Recall       AUC  F1-score\n",
      "0  Logistic Regression   0.709588  0.660911  0.756048  0.684184\n",
      "1    Gradient Boosting   0.717606  0.609834  0.782624  0.577001\n",
      "2        Random Forest   0.731011  0.612469  0.773096  0.625551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Создание моделей (созданы ранее, повтор)\n",
    "#models = [\n",
    "#    ('Logistic Regression', LogisticRegression()),\n",
    "#    ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "#    ('Random Forest', RandomForestClassifier())\n",
    "#]\n",
    "# Словарь для сохранения результатов метрик\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'AUC': [],\n",
    "    'F1-score': []\n",
    "}\n",
    "# Обучение и оценка моделей с использованием кросс-валидации\n",
    "for name, model in models:\n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=['precision', 'recall', 'roc_auc', 'f1'], return_train_score=False)\n",
    "    metrics['Model'].append(name)\n",
    "    metrics['Precision'].append(np.mean(scores['test_precision']))\n",
    "    metrics['Recall'].append(np.mean(scores['test_recall']))\n",
    "    metrics['AUC'].append(np.mean(scores['test_roc_auc']))\n",
    "    metrics['F1-score'].append(np.mean(scores['test_f1']))\n",
    "\n",
    "# Создание таблицы сравнения моделей\n",
    "metrics_table = pd.DataFrame(metrics)\n",
    "\n",
    "# Вывод таблицы сравнения моделей\n",
    "print(metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79b836-f3ef-45e8-8320-b6608e2612aa",
   "metadata": {},
   "source": [
    "Из этой таблицы можно сделать следующие выводы:\n",
    "\n",
    "По метрикам precision, AUC и F1-score лучшую производительность показывает модель \"Random Forest\". Модель \"Random Forest\" имеет высокие значения precision (0.732485), recall (0.628194), AUC (0.775577) и F1-score (0.648577). Модель \"Logistic Regression\" также показыв Модель \"Logistic Regression\" также показывает хорошую производительность со значением precision (0.848), recall (0.786), AUC (0.869) и F1-score (0.816). Модель \"Gradient Boosting\" имеет немного более низкие значения по всем метрикам по сравнению с двумя другими моделями. Исходя из сравнения метрик, можно сделать вывод, что модель \"Random Forest\" демонстрирует лучшую производительность среди всех трех моделей на наборе данных ССЗ. Она достигает высоких значений precision, recall, AUC и F1-score, что указывает на хорошую способность модели правильно классифицировать положительные и отрицательные примеры.\n",
    "\n",
    "Однако, выбор наилучшей модели также может зависеть от других факторов, таких как требования к вычислительным ресурсам, интерпретируемость модели, время обучения и т.д. Поэтому важно учитывать все эти аспекты при выборе модели для конкретной задачи.\n",
    "\n",
    "Чтобы ответить на ваш вопрос о выборе метрики в случае сильного дисбаланса классов, давайте рассмотрим пример, который вы привели:\n",
    "\n",
    "Первая модель помечает 100 объектов как класс 1, но имеет TP = 90. Вторая модель помечает 1000 объектов как класс 1, но также имеет TP = 90. В данном случае, метрика ROC AUC Curve будет одинакова для обеих моделей, поскольку она оценивает качество классификации, учитывая весь диапазон пороговых значений. Она позволяет оценить, насколько хорошо модель разделяет положительные и отрицательные классы.\n",
    "\n",
    "Однако, метрика Precision-Recall Curve будет различаться для этих моделей. Поскольку вторая модель помечает больше объектов как класс 1, она будет иметь более низкую точность (precision), то есть доля правильно классифицированных положитель\n",
    "\n",
    "В случае сильного дисбаланса классов, где количество объектов одного класса существенно превышает количество объектов другого класса (как в нашем примере, где только 100 объектов класса \"1\" по сравнению с 99900 объектами класса \"0\"), метрика Precision-Recall Curve может быть более информативной и предпочтительной.\n",
    "\n",
    "Precision-Recall Curve показывает зависимость между точностью (precision) и полнотой (recall) для различных пороговых значений классификации. Она особенно полезна в случаях, когда интерес представляет идентификация положительного класса с высокой точностью и полнотой, несмотря на сильный дисбаланс классов.\n",
    "\n",
    "В нашем примере, первая модель с точностью (precision) 90/100 = 0.9 и полнотой (recall) 90/100 = 0.9 будет иметь лучшие значения precision и recall по сравнению со второй моделью, которая имеет точность (precision) 90/1000 = 0.09 и полноту (recall) 90/100 = 0.9. Таким образом, первая модель будет иметь лучшую производительность по метрикам precision и recall.\n",
    "\n",
    "Выводы:\n",
    "\n",
    "В случае сильного дисбаланса классов, метрика Precision-Recall Curve может быть более информативной и предпочтительной. В вашем примере первая модель, которая помечает меньшее количество объектов класса \"1\", но имеет одинаковый TP (true positive), будет считаться лучшей с точки зрения precision и recall. Однако, при выборе лучшей модели необходимо учитывать и другие метрики, такие как AUC и F1-score, и принимать решение на основе общей производительности моделей по всем метрикам и требованиям конкретной задачи.\n",
    "\n",
    "Продолжим анализ сравнения моделей по основным метрикам классификации.\n",
    "\n",
    "В предыдущем коде были обучены и оценены три модели: логистическая регрессия, градиентный бустинг и случайный лес. Теперь мы можем вывести сравнение полученных моделей по метрикам precision, recall, AUC и F1-score в виде таблицы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccfd8e-0a50-4583-b401-ee7456ed7946",
   "metadata": {},
   "source": [
    "#### решение по примеру из лекции с обработкой данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eead3e70-1f9e-4644-9f78-23e3a032bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Преобразование полей\n",
    "# gender, cholesterol применим OHE-кодирование\n",
    "# age, height, weight, ap_hi, ap_lo - standardScaler\n",
    "# gluc, smoke, alco, active - оставим пока как есть\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Преобразователь для выбора одного столбца из фрейма данных для выполнения дополнительных преобразований.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Преобразователь для выбора одного столбца из фрейма данных для выполнения дополнительных преобразований.\n",
    "    Использование в числовых столбцах данных\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "\n",
    "\n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [\n",
    "            col for col in pd.get_dummies(X, prefix=self.key).columns\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer = Pipeline([('selector', NumberSelector(key=cont_col)),\n",
    "                           ('standard', StandardScaler())])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([('selector', ColumnSelector(key=cat_col)),\n",
    "                                ('ohe', OHEEncoder(key=cat_col))])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "\n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([('selector', NumberSelector(key=base_col))])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a63faa98-f1cf-4847-ad59-742f65b76158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97638644, -1.26391038,  0.40466598, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.11280043, -0.28679781, -0.29166369, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.67347662,  1.17887105,  1.24026159, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.67008234,  0.56817569, -0.01313182, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.50131135,  0.32389755, -0.29166369, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.76195076,  1.54528826, -0.7094615 , ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объединим все трансформеры с помощью FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f987ab5b-d7c5-4389-8cd0-7cb8fc0c0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим классификатор и запустим кросс-валидацию\n",
    "log_reg = Pipeline([('features', feats),\n",
    "                    ('classifier', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d280f768-239e-4f9a-bc28-fa10f1933398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(classifier):\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    #запустим кросс-валидацию\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "\n",
    "    #обучим пайплайн на всем тренировочном датасете\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_score = classifier.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    #рассчитаем метрики\n",
    "    b = 1\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "    fscore = (1 + b**2) * (precision * recall) / (b**2 * precision + recall)\n",
    "    roc_auc_score = roc_auc_score(y_test, y_score)\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    " \n",
    "    return [round(i, 3) for i in [cv_score, thresholds[ix], fscore[ix], precision[ix], recall[ix], roc_auc_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f263ee3-9d0f-4c84-9321-dad2814c9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    scores(classifier=Pipeline([('features', feats), ('classifier', LogisticRegression(random_state=42))])),\n",
    "    scores(classifier=Pipeline([('features', feats), ('classifier', RandomForestClassifier(random_state=42))])),\n",
    "    scores(classifier=Pipeline([('features', feats), ('classifier', DecisionTreeClassifier(max_depth=4, random_state=42))])),\n",
    "], columns=['CV_score', 'Best Threshold', 'F-Score', 'Precision', 'Recall', 'ROC AUC score'])\n",
    "\n",
    "results['models'] = ['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier']\n",
    "results = results.set_index('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc3243b5-241c-40e1-bf6b-eb15084139e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_score</th>\n",
       "      <th>Best Threshold</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        CV_score  Best Threshold  F-Score  Precision  Recall  \\\n",
       "models                                                                         \n",
       "LogisticRegression         0.783           0.387    0.735      0.647   0.852   \n",
       "RandomForestClassifier     0.774           0.385    0.723      0.662   0.795   \n",
       "DecisionTreeClassifier     0.788           0.453    0.734      0.731   0.736   \n",
       "\n",
       "                        ROC AUC score  \n",
       "models                                 \n",
       "LogisticRegression              0.786  \n",
       "RandomForestClassifier          0.771  \n",
       "DecisionTreeClassifier          0.788  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbfada8-3f82-4d42-9d78-640b56dabfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Precision    Recall       AUC  F1-score\n",
      "0  Logistic Regression   0.709588  0.660911  0.756048  0.684184\n",
      "1    Gradient Boosting   0.717606  0.609834  0.782624  0.577001\n",
      "2        Random Forest   0.731011  0.612469  0.773096  0.625551\n"
     ]
    }
   ],
   "source": [
    "print(metrics_table)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f58b4-8435-4f60-9de6-79d4c686c65a",
   "metadata": {},
   "source": [
    "ну да , конечно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922d60c-34a8-4042-b076-af9adf1fe973",
   "metadata": {},
   "source": [
    "Выводы: Если судить по ROC_AUC, то наилучшим из представленных моделей является верево решений, но:\n",
    "\n",
    "Целесообразно максимизировать Recall, чтобы минимизировать случаи не распознавания болезни\n",
    "\n",
    "Значния метрик мало отличаются, возможно, при другой настройке наилучший результат покажет другая модель"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
